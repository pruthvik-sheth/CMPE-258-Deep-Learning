{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2z6xCVYLyVbxvnUxPDLrw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Part 2: PyTorch Implementation\n","\n","Now let's explore similar tensor operations in PyTorch. First, we'll set up the PyTorch environment and cover basic tensor operations."],"metadata":{"id":"y1FqDPm3I1Ep"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XieBnCgBHwX-","executionInfo":{"status":"ok","timestamp":1741762578788,"user_tz":420,"elapsed":8058,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"b8db994a-e9d3-4359-c6de-380d49c95827"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.5.1+cu124\n","CUDA Available: False\n","Scalar: tensor(3)\n","Shape: torch.Size([])\n","Datatype: torch.int64\n","\n","Vector: tensor([1, 2, 3, 4])\n","Shape: torch.Size([4])\n","\n","Matrix: tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]])\n","Shape: torch.Size([3, 2])\n","\n","3D Tensor: tensor([[[1, 2],\n","         [3, 4]],\n","\n","        [[5, 6],\n","         [7, 8]]])\n","Shape: torch.Size([2, 2, 2])\n","\n","Float tensor: tensor([1.2000, 3.4000, 5.6000])\n","Int tensor: tensor([1, 2, 3], dtype=torch.int32)\n","Boolean tensor: tensor([ True, False,  True])\n","\n","Zeros tensor: tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","\n","Ones tensor: tensor([[[1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.]]])\n","\n","Random normal tensor: tensor([[ 0.3367,  0.1288,  0.2345],\n","        [ 0.2303, -1.1229, -0.1863],\n","        [ 2.2082, -0.6380,  0.4617]])\n","\n","Random uniform tensor: tensor([[0.2696, 0.4414, 0.2969],\n","        [0.8317, 0.1053, 0.2695]])\n","\n","CPU Tensor: tensor([1, 2, 3])\n","No GPU available, skipping CUDA tensor examples\n"]}],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Check PyTorch version\n","print(f\"PyTorch version: {torch.__version__}\")\n","\n","# Check for GPU availability\n","print(f\"CUDA Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n","\n","# Set random seed for reproducibility\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# Create basic tensors\n","# From Python list\n","scalar = torch.tensor(3)\n","vector = torch.tensor([1, 2, 3, 4])\n","matrix = torch.tensor([[1, 2], [3, 4], [5, 6]])\n","tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n","\n","# Print tensor information\n","print(\"Scalar:\", scalar)\n","print(\"Shape:\", scalar.shape)\n","print(\"Datatype:\", scalar.dtype)\n","print(\"\\nVector:\", vector)\n","print(\"Shape:\", vector.shape)\n","print(\"\\nMatrix:\", matrix)\n","print(\"Shape:\", matrix.shape)\n","print(\"\\n3D Tensor:\", tensor_3d)\n","print(\"Shape:\", tensor_3d.shape)\n","\n","# Creating tensors with specific types\n","float_tensor = torch.tensor([1.2, 3.4, 5.6], dtype=torch.float32)\n","int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n","bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n","\n","print(\"\\nFloat tensor:\", float_tensor)\n","print(\"Int tensor:\", int_tensor)\n","print(\"Boolean tensor:\", bool_tensor)\n","\n","# Create tensors with PyTorch functions\n","zeros = torch.zeros(2, 3)\n","ones = torch.ones(2, 2, 2)\n","random_normal = torch.randn(3, 3)  # mean=0, std=1\n","random_uniform = torch.rand(2, 3)  # uniform from [0, 1)\n","\n","print(\"\\nZeros tensor:\", zeros)\n","print(\"\\nOnes tensor:\", ones)\n","print(\"\\nRandom normal tensor:\", random_normal)\n","print(\"\\nRandom uniform tensor:\", random_uniform)\n","\n","# Device management\n","cpu_tensor = torch.tensor([1, 2, 3], device='cpu')\n","print(\"\\nCPU Tensor:\", cpu_tensor)\n","\n","# Only create CUDA tensor if GPU is available\n","if torch.cuda.is_available():\n","    gpu_tensor = torch.tensor([1, 2, 3], device='cuda')\n","    print(\"GPU Tensor:\", gpu_tensor)\n","\n","    # Moving tensors between devices\n","    moved_to_cpu = gpu_tensor.cpu()\n","    print(\"GPU Tensor moved to CPU:\", moved_to_cpu)\n","else:\n","    print(\"No GPU available, skipping CUDA tensor examples\")"]},{"cell_type":"markdown","source":["## Basic Tensor Operations in PyTorch\n","\n","Let's explore fundamental tensor operations in PyTorch:\n","- Mathematical operations\n","- Matrix multiplication\n","- Reshaping and transposing\n","- View vs Copy operations (a key concept in PyTorch)"],"metadata":{"id":"exspfmXsJCMV"}},{"cell_type":"code","source":["# Create sample tensors\n","a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n","b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n","\n","# Basic mathematical operations\n","addition = a + b  # Element-wise addition\n","subtraction = a - b  # Element-wise subtraction\n","multiplication = a * b  # Element-wise multiplication\n","division = a / b  # Element-wise division\n","\n","print(\"Tensor a:\\n\", a)\n","print(\"Tensor b:\\n\", b)\n","print(\"\\nAddition (a + b):\\n\", addition)\n","print(\"\\nSubtraction (a - b):\\n\", subtraction)\n","print(\"\\nMultiplication (a * b):\\n\", multiplication)\n","print(\"\\nDivision (a / b):\\n\", division)\n","\n","# Matrix multiplication\n","matrix_mult = torch.matmul(a, b)\n","matrix_mult_2 = a @ b  # Python 3.5+ syntax\n","\n","print(\"\\nMatrix multiplication (torch.matmul(a, b)):\\n\", matrix_mult)\n","print(\"\\nMatrix multiplication (a @ b):\\n\", matrix_mult_2)\n","\n","# Reshaping tensors\n","c = torch.tensor([1, 2, 3, 4, 5, 6])\n","reshaped = c.reshape(2, 3)\n","reshaped_2 = c.reshape(3, 2)\n","\n","print(\"\\nOriginal tensor c:\", c)\n","print(\"Shape:\", c.shape)\n","print(\"\\nReshaped [2,3]:\\n\", reshaped)\n","print(\"\\nReshaped [3,2]:\\n\", reshaped_2)\n","\n","# Transposing tensors\n","d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","transposed = d.t()  # Only works for 2D tensors\n","transposed_any_dim = d.transpose(0, 1)  # Works for any dimension\n","\n","print(\"\\nOriginal tensor d:\\n\", d)\n","print(\"Shape:\", d.shape)\n","print(\"\\nTransposed:\\n\", transposed)\n","print(\"Shape:\", transposed.shape)\n","\n","# View vs Copy - a key concept in PyTorch\n","original = torch.tensor([[1, 2, 3, 4],\n","                         [5, 6, 7, 8]])\n","\n","# View creates a new tensor that shares the same underlying data\n","view = original.view(4, 2)\n","\n","# Clone creates a copy with new memory\n","copy = original.clone().view(4, 2)\n","\n","print(\"\\nOriginal tensor:\\n\", original)\n","print(\"View:\\n\", view)\n","print(\"Copy:\\n\", copy)\n","\n","# Modifying the original affects the view but not the copy\n","original[0, 0] = 99\n","print(\"\\nAfter modifying original[0,0] = 99:\")\n","print(\"Original tensor:\\n\", original)\n","print(\"View (should be affected):\\n\", view)\n","print(\"Copy (should not be affected):\\n\", copy)\n","\n","# Contiguous tensors\n","# After operations like transpose, tensors may not be contiguous in memory\n","e = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","e_t = e.t()\n","print(\"\\nIs transposed tensor contiguous?\", e_t.is_contiguous())\n","\n","# Make contiguous using contiguous() method\n","e_t_cont = e_t.contiguous()\n","print(\"After calling contiguous():\", e_t_cont.is_contiguous())\n","\n","# Advanced indexing and slicing\n","f = torch.randn(4, 5)\n","print(\"\\nRandom tensor f:\\n\", f)\n","print(\"\\nFirst row:\", f[0])\n","print(\"\\nFirst column:\", f[:, 0])\n","print(\"\\nSubmatrix (first 2 rows, first 3 columns):\\n\", f[:2, :3])\n","\n","# Boolean indexing\n","mask = f > 0\n","positive_values = f[mask]\n","print(\"\\nBoolean mask (f > 0):\\n\", mask)\n","print(\"\\nPositive values only:\", positive_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_7gKeJ2I5L0","executionInfo":{"status":"ok","timestamp":1741762614534,"user_tz":420,"elapsed":68,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"450406e3-218c-4f3a-a1ad-52b73c47783b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor a:\n"," tensor([[1., 2.],\n","        [3., 4.]])\n","Tensor b:\n"," tensor([[5., 6.],\n","        [7., 8.]])\n","\n","Addition (a + b):\n"," tensor([[ 6.,  8.],\n","        [10., 12.]])\n","\n","Subtraction (a - b):\n"," tensor([[-4., -4.],\n","        [-4., -4.]])\n","\n","Multiplication (a * b):\n"," tensor([[ 5., 12.],\n","        [21., 32.]])\n","\n","Division (a / b):\n"," tensor([[0.2000, 0.3333],\n","        [0.4286, 0.5000]])\n","\n","Matrix multiplication (torch.matmul(a, b)):\n"," tensor([[19., 22.],\n","        [43., 50.]])\n","\n","Matrix multiplication (a @ b):\n"," tensor([[19., 22.],\n","        [43., 50.]])\n","\n","Original tensor c: tensor([1, 2, 3, 4, 5, 6])\n","Shape: torch.Size([6])\n","\n","Reshaped [2,3]:\n"," tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","\n","Reshaped [3,2]:\n"," tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]])\n","\n","Original tensor d:\n"," tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","Shape: torch.Size([2, 3])\n","\n","Transposed:\n"," tensor([[1, 4],\n","        [2, 5],\n","        [3, 6]])\n","Shape: torch.Size([3, 2])\n","\n","Original tensor:\n"," tensor([[1, 2, 3, 4],\n","        [5, 6, 7, 8]])\n","View:\n"," tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","Copy:\n"," tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","\n","After modifying original[0,0] = 99:\n","Original tensor:\n"," tensor([[99,  2,  3,  4],\n","        [ 5,  6,  7,  8]])\n","View (should be affected):\n"," tensor([[99,  2],\n","        [ 3,  4],\n","        [ 5,  6],\n","        [ 7,  8]])\n","Copy (should not be affected):\n"," tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","\n","Is transposed tensor contiguous? False\n","After calling contiguous(): True\n","\n","Random tensor f:\n"," tensor([[-0.4934,  0.2415, -1.1109,  0.0915, -1.0892],\n","        [-0.3553, -0.9138, -0.6581,  0.0780,  0.5258],\n","        [-0.4880,  1.1914, -1.3864, -1.2862, -1.4032],\n","        [ 0.0360, -0.0635,  0.6756, -0.0978,  1.8446]])\n","\n","First row: tensor([-0.4934,  0.2415, -1.1109,  0.0915, -1.0892])\n","\n","First column: tensor([-0.4934, -0.3553, -0.4880,  0.0360])\n","\n","Submatrix (first 2 rows, first 3 columns):\n"," tensor([[-0.4934,  0.2415, -1.1109],\n","        [-0.3553, -0.9138, -0.6581]])\n","\n","Boolean mask (f > 0):\n"," tensor([[False,  True, False,  True, False],\n","        [False, False, False,  True,  True],\n","        [False,  True, False, False, False],\n","        [ True, False,  True, False,  True]])\n","\n","Positive values only: tensor([0.2415, 0.0915, 0.0780, 0.5258, 1.1914, 0.0360, 0.6756, 1.8446])\n"]}]},{"cell_type":"markdown","source":["## Broadcasting in PyTorch\n","\n","PyTorch also follows the same broadcasting rules as NumPy and TensorFlow, allowing operations between tensors of different shapes when certain conditions are met.\n","\n","Let's explore how broadcasting works in PyTorch:"],"metadata":{"id":"l8bkLBIqJHty"}},{"cell_type":"code","source":["# Create tensors of different shapes\n","matrix = torch.tensor([[1, 2, 3],\n","                       [4, 5, 6]], dtype=torch.float32)  # Shape: (2, 3)\n","vector = torch.tensor([10, 20, 30], dtype=torch.float32)  # Shape: (3,)\n","scalar = torch.tensor(5, dtype=torch.float32)            # Shape: ()\n","\n","# Broadcasting with addition\n","matrix_plus_vector = matrix + vector\n","matrix_plus_scalar = matrix + scalar\n","\n","print(\"Matrix shape:\", matrix.shape)\n","print(\"Vector shape:\", vector.shape)\n","print(\"Scalar shape:\", scalar.shape)\n","print(\"\\nMatrix:\\n\", matrix)\n","print(\"\\nVector:\", vector)\n","print(\"\\nScalar:\", scalar)\n","\n","print(\"\\nMatrix + Vector (broadcasting):\\n\", matrix_plus_vector)\n","print(\"\\nMatrix + Scalar (broadcasting):\\n\", matrix_plus_scalar)\n","\n","# More complex broadcasting example\n","a = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)  # Shape: (3, 2)\n","b = torch.tensor([[10], [20], [30]], dtype=torch.float32)        # Shape: (3, 1)\n","c = a + b  # Broadcasting\n","\n","print(\"\\nTensor a shape:\", a.shape)\n","print(\"Tensor b shape:\", b.shape)\n","print(\"Result shape (a + b):\", c.shape)\n","print(\"\\nTensor a:\\n\", a)\n","print(\"\\nTensor b:\\n\", b)\n","print(\"\\nResult (a + b):\\n\", c)\n","\n","# Broadcasting in matrix multiplication\n","# Create a batch of matrices\n","batch_a = torch.randn(3, 2, 4)  # 3 matrices of shape 2x4\n","batch_b = torch.randn(1, 4, 5)  # 1 matrix of shape 4x5 (will be broadcast)\n","\n","# Perform batched matrix multiplication\n","batch_result = torch.bmm(batch_a, batch_b.expand(3, 4, 5))\n","print(\"\\nBatch matrix multiplication result shape:\", batch_result.shape)\n","\n","# Broadcasting with unsqueeze\n","d = torch.tensor([1, 2, 3])\n","e = torch.tensor([4, 5, 6])\n","outer_product = d.unsqueeze(1) * e.unsqueeze(0)\n","\n","print(\"\\nOriginal vector d:\", d)\n","print(\"Original vector e:\", e)\n","print(\"d.unsqueeze(1) shape:\", d.unsqueeze(1).shape)\n","print(\"e.unsqueeze(0) shape:\", e.unsqueeze(0).shape)\n","print(\"Outer product (d.unsqueeze(1) * e.unsqueeze(0)):\\n\", outer_product)\n","\n","# Visualize broadcasting\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","# Original matrix\n","axes[0].imshow(matrix.numpy(), cmap='viridis')\n","axes[0].set_title('Matrix (2,3)')\n","axes[0].set_xticks(np.arange(3))\n","axes[0].set_yticks(np.arange(2))\n","\n","# Vector (broadcasted)\n","broadcasted_vector = np.tile(vector.numpy(), (2, 1))\n","axes[1].imshow(broadcasted_vector, cmap='plasma')\n","axes[1].set_title('Vector (3,) â†’ (2,3)')\n","axes[1].set_xticks(np.arange(3))\n","axes[1].set_yticks(np.arange(2))\n","\n","# Result\n","axes[2].imshow(matrix_plus_vector.numpy(), cmap='inferno')\n","axes[2].set_title('Matrix + Vector = (2,3)')\n","axes[2].set_xticks(np.arange(3))\n","axes[2].set_yticks(np.arange(2))\n","\n","for ax in axes:\n","    for i in range(2):\n","        for j in range(3):\n","            if ax == axes[0]:\n","                text = f\"{matrix[i, j].item()}\"\n","            elif ax == axes[1]:\n","                text = f\"{vector[j].item()}\"\n","            else:\n","                text = f\"{matrix_plus_vector[i, j].item()}\"\n","            ax.text(j, i, text, ha=\"center\", va=\"center\", color=\"w\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3PK0Hd-tJFQx","executionInfo":{"status":"ok","timestamp":1741762634134,"user_tz":420,"elapsed":689,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"d643d863-5d8e-40e0-8264-2b33d5705281"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix shape: torch.Size([2, 3])\n","Vector shape: torch.Size([3])\n","Scalar shape: torch.Size([])\n","\n","Matrix:\n"," tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","\n","Vector: tensor([10., 20., 30.])\n","\n","Scalar: tensor(5.)\n","\n","Matrix + Vector (broadcasting):\n"," tensor([[11., 22., 33.],\n","        [14., 25., 36.]])\n","\n","Matrix + Scalar (broadcasting):\n"," tensor([[ 6.,  7.,  8.],\n","        [ 9., 10., 11.]])\n","\n","Tensor a shape: torch.Size([3, 2])\n","Tensor b shape: torch.Size([3, 1])\n","Result shape (a + b): torch.Size([3, 2])\n","\n","Tensor a:\n"," tensor([[1., 2.],\n","        [3., 4.],\n","        [5., 6.]])\n","\n","Tensor b:\n"," tensor([[10.],\n","        [20.],\n","        [30.]])\n","\n","Result (a + b):\n"," tensor([[11., 12.],\n","        [23., 24.],\n","        [35., 36.]])\n","\n","Batch matrix multiplication result shape: torch.Size([3, 2, 5])\n","\n","Original vector d: tensor([1, 2, 3])\n","Original vector e: tensor([4, 5, 6])\n","d.unsqueeze(1) shape: torch.Size([3, 1])\n","e.unsqueeze(0) shape: torch.Size([1, 3])\n","Outer product (d.unsqueeze(1) * e.unsqueeze(0)):\n"," tensor([[ 4,  5,  6],\n","        [ 8, 10, 12],\n","        [12, 15, 18]])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x500 with 3 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Advanced Indexing and Slicing in PyTorch\n","\n","PyTorch provides powerful indexing capabilities that allow for complex data manipulation:\n","- Boolean masking\n","- Index tensors\n","- Fancy indexing\n","- Scatter and gather operations"],"metadata":{"id":"F41BqDpcK82B"}},{"cell_type":"markdown","source":["## Advanced Indexing and Slicing in PyTorch\n","\n","PyTorch provides powerful indexing capabilities that allow for complex data manipulation:\n","- Boolean masking\n","- Index tensors\n","- Fancy indexing\n","- Scatter and gather operations"],"metadata":{"id":"8CCpLYuxK_wo"}},{"cell_type":"code","source":["# Create a sample tensor\n","tensor = torch.tensor([\n","    [[1, 2, 3], [4, 5, 6]],\n","    [[7, 8, 9], [10, 11, 12]],\n","    [[13, 14, 15], [16, 17, 18]]\n","])\n","print(\"Original tensor shape:\", tensor.shape)\n","print(\"Original tensor:\\n\", tensor)\n","\n","# Basic slicing\n","print(\"\\nFirst element (tensor[0]):\\n\", tensor[0])\n","print(\"\\nFirst row of each 2D slice (tensor[:, 0]):\\n\", tensor[:, 0])\n","print(\"\\nFirst column of each row (tensor[:, :, 0]):\\n\", tensor[:, :, 0])\n","\n","# Slicing with ranges\n","print(\"\\nFirst two elements (tensor[0:2]):\\n\", tensor[0:2])\n","print(\"\\nLast dimension with step (tensor[:, :, ::2]):\\n\", tensor[:, :, ::2])\n","\n","# Boolean masking\n","mask = tensor > 9\n","masked_tensor = tensor[mask]\n","print(\"\\nBoolean mask (tensor > 9):\\n\", mask)\n","print(\"Values where tensor > 9:\", masked_tensor)\n","\n","# Using index tensors\n","indices = torch.tensor([0, 2])  # Select first and third elements\n","selected = tensor[indices]\n","print(\"\\nSelected elements using indices tensor:\", selected.shape)\n","print(selected)\n","\n","# Advanced indexing\n","rows = torch.tensor([0, 1, 2])\n","cols = torch.tensor([0, 1, 0])\n","selected_rows_cols = tensor[rows, cols]\n","print(\"\\nSelected using row and column indices:\", selected_rows_cols.shape)\n","print(selected_rows_cols)\n","\n","# Gather operation (similar to tf.gather)\n","dim = 0  # Dimension to gather along\n","index = torch.tensor([[0, 1], [2, 0]])  # Indices to gather\n","gathered = torch.gather(tensor[:, 0, :], dim, index)\n","print(\"\\nGathered tensor along dimension\", dim, \":\\n\", gathered)\n","\n","# Scatter operation - fixed version\n","# Make sure dtype matches between source and destination\n","scatter_src = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n","scatter_idx = torch.tensor([[0, 1], [2, 3]], dtype=torch.long)  # Indices must be long\n","scatter_out = torch.zeros(4, 4)\n","scatter_out.scatter_(0, scatter_idx, scatter_src)  # dim, index, src\n","print(\"\\nScattered tensor:\\n\", scatter_out)\n","\n","# Where operation (conditional selection)\n","condition = tensor > 9\n","result = torch.where(condition, tensor * 2, tensor)\n","print(\"\\nConditional selection (double values > 9):\\n\", result)\n","\n","# Masking and replacing values\n","tensor_copy = tensor.clone()\n","tensor_copy[tensor_copy > 9] = 0\n","print(\"\\nReplacing values > 9 with zeros:\\n\", tensor_copy)\n","\n","# Non-contiguous slicing and indexing\n","non_contiguous = tensor[::2, :, ::2]  # Skip every other element in 1st and 3rd dims\n","print(\"\\nNon-contiguous slice:\", non_contiguous.shape)\n","print(\"Is contiguous:\", non_contiguous.is_contiguous())\n","contiguous_version = non_contiguous.contiguous()\n","print(\"After making contiguous:\", contiguous_version.is_contiguous())"],"metadata":{"id":"yk9O8kvNJJ5O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741763405265,"user_tz":420,"elapsed":22,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"b7f9afb5-6eb6-4867-cb7e-602dbd6031fa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tensor shape: torch.Size([3, 2, 3])\n","Original tensor:\n"," tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]],\n","\n","        [[13, 14, 15],\n","         [16, 17, 18]]])\n","\n","First element (tensor[0]):\n"," tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","\n","First row of each 2D slice (tensor[:, 0]):\n"," tensor([[ 1,  2,  3],\n","        [ 7,  8,  9],\n","        [13, 14, 15]])\n","\n","First column of each row (tensor[:, :, 0]):\n"," tensor([[ 1,  4],\n","        [ 7, 10],\n","        [13, 16]])\n","\n","First two elements (tensor[0:2]):\n"," tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]]])\n","\n","Last dimension with step (tensor[:, :, ::2]):\n"," tensor([[[ 1,  3],\n","         [ 4,  6]],\n","\n","        [[ 7,  9],\n","         [10, 12]],\n","\n","        [[13, 15],\n","         [16, 18]]])\n","\n","Boolean mask (tensor > 9):\n"," tensor([[[False, False, False],\n","         [False, False, False]],\n","\n","        [[False, False, False],\n","         [ True,  True,  True]],\n","\n","        [[ True,  True,  True],\n","         [ True,  True,  True]]])\n","Values where tensor > 9: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18])\n","\n","Selected elements using indices tensor: torch.Size([2, 2, 3])\n","tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[13, 14, 15],\n","         [16, 17, 18]]])\n","\n","Selected using row and column indices: torch.Size([3, 3])\n","tensor([[ 1,  2,  3],\n","        [10, 11, 12],\n","        [13, 14, 15]])\n","\n","Gathered tensor along dimension 0 :\n"," tensor([[ 1,  8],\n","        [13,  2]])\n","\n","Scattered tensor:\n"," tensor([[1., 0., 0., 0.],\n","        [0., 2., 0., 0.],\n","        [3., 0., 0., 0.],\n","        [0., 4., 0., 0.]])\n","\n","Conditional selection (double values > 9):\n"," tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [20, 22, 24]],\n","\n","        [[26, 28, 30],\n","         [32, 34, 36]]])\n","\n","Replacing values > 9 with zeros:\n"," tensor([[[1, 2, 3],\n","         [4, 5, 6]],\n","\n","        [[7, 8, 9],\n","         [0, 0, 0]],\n","\n","        [[0, 0, 0],\n","         [0, 0, 0]]])\n","\n","Non-contiguous slice: torch.Size([2, 2, 2])\n","Is contiguous: False\n","After making contiguous: True\n"]}]},{"cell_type":"markdown","source":["## Autograd: Automatic Differentiation in PyTorch\n","\n","One of PyTorch's key features is its automatic differentiation engine called Autograd. It records operations on tensors and builds a computational graph, allowing for efficient calculation of gradients.\n","\n","Let's explore how to compute gradients in PyTorch:"],"metadata":{"id":"R_6jMS8-MOcS"}},{"cell_type":"code","source":["# Create tensors with gradients enabled\n","x = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n","\n","# Simple function: f(x) = x^2\n","y = x.pow(2)\n","\n","# Compute gradient\n","# We need to provide a gradient argument for backward\n","# For a tensor with multiple elements, we often want the sum\n","z = y.sum()\n","z.backward()\n","\n","print(\"Tensor x:\\n\", x)\n","print(\"Gradient w.r.t. x (should be 2x):\\n\", x.grad)\n","\n","# Reset gradients (they accumulate by default)\n","x.grad.zero_()\n","\n","# More complex expression\n","y = x * x + 3 * x + 5\n","z = y.mean()  # Average over all elements\n","z.backward()\n","\n","print(\"\\nFunction: xÂ² + 3x + 5, averaged\")\n","print(\"Gradient w.r.t. x:\\n\", x.grad)\n","\n","# Multiple inputs and outputs\n","x1 = torch.tensor(2.0, requires_grad=True)\n","x2 = torch.tensor(3.0, requires_grad=True)\n","\n","# Function with multiple inputs\n","y1 = x1**2 + x2\n","y2 = x1 * x2**2\n","\n","# To compute gradients for multiple outputs, we calculate them one at a time\n","y1.backward(retain_graph=True)  # retain_graph=True keeps the computational graph\n","print(\"\\nInputs: x1 =\", x1.item(), \", x2 =\", x2.item())\n","print(\"Outputs: y1 = x1Â² + x2 =\", y1.item(), \", y2 = x1 * x2Â² =\", y2.item())\n","print(\"âˆ‚y1/âˆ‚x1 =\", x1.grad.item())  # Gradient of y1 w.r.t. x1\n","print(\"âˆ‚y1/âˆ‚x2 =\", x2.grad.item())  # Gradient of y1 w.r.t. x2\n","\n","# Reset gradients before computing the next gradients\n","x1.grad.zero_()\n","x2.grad.zero_()\n","\n","# Now compute gradients for y2\n","y2.backward()\n","print(\"âˆ‚y2/âˆ‚x1 =\", x1.grad.item())  # Gradient of y2 w.r.t. x1\n","print(\"âˆ‚y2/âˆ‚x2 =\", x2.grad.item())  # Gradient of y2 w.r.t. x2\n","\n","# Higher-order derivatives\n","x3 = torch.tensor(5.0, requires_grad=True)\n","\n","# First-order derivative\n","y3 = x3**3\n","y3.backward(create_graph=True)  # create_graph=True allows for higher-order gradients\n","first_derivative = x3.grad.clone()  # Should be 3xÂ²\n","\n","# Second-order derivative\n","x3.grad.backward()  # Differentiate the first derivative\n","second_derivative = x3.grad  # Should be 6x\n","\n","print(\"\\nInput x3 =\", x3.item())\n","print(\"f(x) = xÂ³ =\", y3.item())\n","print(\"First derivative (3xÂ²) =\", first_derivative.item())\n","print(\"Second derivative (6x) =\", second_derivative.item())\n","\n","# Using with neural networks\n","# Create a simple model\n","inputs = torch.randn(32, 10)\n","w = torch.randn(10, 5, requires_grad=True)\n","b = torch.zeros(5, requires_grad=True)\n","\n","# Forward pass\n","outputs = inputs @ w + b\n","loss = outputs.pow(2).mean()\n","\n","# Backward pass\n","loss.backward()\n","\n","print(\"\\nSimple Model Loss:\", loss.item())\n","print(\"Gradient of w shape:\", w.grad.shape)\n","print(\"Gradient of b shape:\", b.grad.shape)\n","\n","# No grad context for inference\n","with torch.no_grad():\n","    inference_output = inputs @ w + b\n","    # No gradients are computed or stored\n","\n","print(\"\\nInference output computed with torch.no_grad():\", inference_output.shape)\n","print(\"requires_grad =\", inference_output.requires_grad)  # Should be False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67VlRlwdK-5P","executionInfo":{"status":"ok","timestamp":1741763507694,"user_tz":420,"elapsed":64,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"a1792550-c596-4d45-ce3c-79f7daf55bf2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor x:\n"," tensor([[1., 2.],\n","        [3., 4.]], requires_grad=True)\n","Gradient w.r.t. x (should be 2x):\n"," tensor([[2., 4.],\n","        [6., 8.]])\n","\n","Function: xÂ² + 3x + 5, averaged\n","Gradient w.r.t. x:\n"," tensor([[1.2500, 1.7500],\n","        [2.2500, 2.7500]])\n","\n","Inputs: x1 = 2.0 , x2 = 3.0\n","Outputs: y1 = x1Â² + x2 = 7.0 , y2 = x1 * x2Â² = 18.0\n","âˆ‚y1/âˆ‚x1 = 4.0\n","âˆ‚y1/âˆ‚x2 = 1.0\n","âˆ‚y2/âˆ‚x1 = 9.0\n","âˆ‚y2/âˆ‚x2 = 12.0\n","\n","Input x3 = 5.0\n","f(x) = xÂ³ = 125.0\n","First derivative (3xÂ²) = 75.0\n","Second derivative (6x) = 105.0\n","\n","Simple Model Loss: 5.09912633895874\n","Gradient of w shape: torch.Size([10, 5])\n","Gradient of b shape: torch.Size([5])\n","\n","Inference output computed with torch.no_grad(): torch.Size([32, 5])\n","requires_grad = False\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1201.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]}]},{"cell_type":"markdown","source":["## Einstein Summation (einsum) in PyTorch\n","\n","Just like in TensorFlow, PyTorch also provides the powerful `einsum` operation for expressing complex tensor operations concisely.\n","\n","Let's explore how to use einsum in PyTorch:"],"metadata":{"id":"KJp6Ze3pNK4t"}},{"cell_type":"code","source":["# Create sample tensors\n","a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n","b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n","c = torch.tensor([1, 2, 3], dtype=torch.float32)\n","d = torch.tensor([4, 5, 6], dtype=torch.float32)\n","\n","print(\"Tensor a:\\n\", a)\n","print(\"Shape:\", a.shape)\n","print(\"\\nTensor b:\\n\", b)\n","print(\"Shape:\", b.shape)\n","\n","# Matrix transpose using einsum\n","# 'ij->ji' means \"take indices i,j and return them as j,i\"\n","transpose_a = torch.einsum('ij->ji', a)\n","print(\"\\nTranspose of a using einsum ('ij->ji'):\\n\", transpose_a)\n","print(\"Standard transpose:\\n\", a.t())\n","\n","# Matrix multiplication using einsum\n","# 'ij,jk->ik' means \"sum over j in the first and second tensors\"\n","matmul_ab = torch.einsum('ij,jk->ik', a, b)\n","print(\"\\nMatrix multiplication using einsum ('ij,jk->ik'):\\n\", matmul_ab)\n","print(\"Standard matmul:\\n\", a @ b)\n","\n","# Dot product of vectors using einsum\n","# 'i,i->' means \"sum over i in both tensors\"\n","dot_cd = torch.einsum('i,i->', c, d)\n","print(\"\\nDot product using einsum ('i,i->'):\", dot_cd.item())\n","print(\"Standard dot product:\", torch.dot(c, d).item())\n","\n","# Outer product of vectors using einsum\n","# 'i,j->ij' means \"no summation, just create all combinations\"\n","outer_cd = torch.einsum('i,j->ij', c, d)\n","print(\"\\nOuter product using einsum ('i,j->ij'):\\n\", outer_cd)\n","print(\"Standard outer product:\\n\", torch.outer(c, d))\n","\n","# Batch matrix multiplication\n","# Create 3D tensors (batch of matrices)\n","batch_a = torch.randn(3, 2, 4)  # 3 matrices of shape 2x4\n","batch_b = torch.randn(3, 4, 5)  # 3 matrices of shape 4x5\n","\n","# 'bij,bjk->bik' means \"for each item in batch, do matrix multiplication\"\n","batch_matmul = torch.einsum('bij,bjk->bik', batch_a, batch_b)\n","print(\"\\nBatch matrix multiplication shape:\", batch_matmul.shape)\n","print(\"Should be equivalent to standard batch matmul:\", torch.bmm(batch_a, batch_b).shape)\n","\n","# Trace of a matrix (sum of diagonal elements)\n","trace_a = torch.einsum('ii->', a)\n","print(\"\\nTrace of a using einsum ('ii->'):\", trace_a.item())\n","print(\"Standard trace:\", torch.trace(a).item())\n","\n","# Element-wise multiplication\n","element_mult = torch.einsum('ij,ij->ij', a, b)\n","print(\"\\nElement-wise multiplication using einsum ('ij,ij->ij'):\\n\", element_mult)\n","print(\"Standard element-wise multiplication:\\n\", a * b)\n","\n","# Diagonal extraction\n","diag_a = torch.einsum('ii->i', a)\n","print(\"\\nDiagonal of a using einsum ('ii->i'):\", diag_a)\n","print(\"Standard diagonal:\", torch.diag(a))\n","\n","# Sum all elements\n","sum_a = torch.einsum('ij->', a)\n","print(\"\\nSum of all elements using einsum ('ij->'):\", sum_a.item())\n","print(\"Standard sum:\", a.sum().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57Wg7SrqMfUe","executionInfo":{"status":"ok","timestamp":1741763691350,"user_tz":420,"elapsed":125,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"e901b573-4f3d-4079-d1a5-2ce9f5e9f876"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor a:\n"," tensor([[1., 2.],\n","        [3., 4.]])\n","Shape: torch.Size([2, 2])\n","\n","Tensor b:\n"," tensor([[5., 6.],\n","        [7., 8.]])\n","Shape: torch.Size([2, 2])\n","\n","Transpose of a using einsum ('ij->ji'):\n"," tensor([[1., 3.],\n","        [2., 4.]])\n","Standard transpose:\n"," tensor([[1., 3.],\n","        [2., 4.]])\n","\n","Matrix multiplication using einsum ('ij,jk->ik'):\n"," tensor([[19., 22.],\n","        [43., 50.]])\n","Standard matmul:\n"," tensor([[19., 22.],\n","        [43., 50.]])\n","\n","Dot product using einsum ('i,i->'): 32.0\n","Standard dot product: 32.0\n","\n","Outer product using einsum ('i,j->ij'):\n"," tensor([[ 4.,  5.,  6.],\n","        [ 8., 10., 12.],\n","        [12., 15., 18.]])\n","Standard outer product:\n"," tensor([[ 4.,  5.,  6.],\n","        [ 8., 10., 12.],\n","        [12., 15., 18.]])\n","\n","Batch matrix multiplication shape: torch.Size([3, 2, 5])\n","Should be equivalent to standard batch matmul: torch.Size([3, 2, 5])\n","\n","Trace of a using einsum ('ii->'): 5.0\n","Standard trace: 5.0\n","\n","Element-wise multiplication using einsum ('ij,ij->ij'):\n"," tensor([[ 5., 12.],\n","        [21., 32.]])\n","Standard element-wise multiplication:\n"," tensor([[ 5., 12.],\n","        [21., 32.]])\n","\n","Diagonal of a using einsum ('ii->i'): tensor([1., 4.])\n","Standard diagonal: tensor([1., 4.])\n","\n","Sum of all elements using einsum ('ij->'): 10.0\n","Standard sum: 10.0\n"]}]},{"cell_type":"markdown","source":["## Custom Operations and Memory Management in PyTorch\n","\n","PyTorch allows you to define custom operations and provides fine-grained control over memory management. Let's explore:\n","\n","1. How to create custom autograd functions\n","2. How to optimize memory usage with in-place operations\n","3. Performance considerations with CPU vs. GPU operations"],"metadata":{"id":"3u1nMLNrNN-Q"}},{"cell_type":"code","source":["import time\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# 1. Custom Autograd Function\n","class CustomReLU(torch.autograd.Function):\n","    \"\"\"\n","    Custom implementation of ReLU with custom gradient.\n","    \"\"\"\n","    @staticmethod\n","    def forward(ctx, input):\n","        ctx.save_for_backward(input)\n","        return input.clamp(min=0)  # Forward pass: max(0, x)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        input, = ctx.saved_tensors\n","        grad_input = grad_output.clone()\n","        grad_input[input < 0] = 0  # Backward pass: gradient is 0 where input < 0\n","        return grad_input\n","\n","# Use our custom ReLU\n","custom_relu = CustomReLU.apply\n","\n","# Test the function\n","test_input = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0], requires_grad=True)\n","result = custom_relu(test_input)\n","result.sum().backward()\n","\n","print(\"Input:\", test_input.data)\n","print(\"Output of custom ReLU:\", result.data)\n","print(\"Gradient:\", test_input.grad)\n","\n","# Reset the gradient\n","test_input.grad.zero_()\n","\n","# Compare with standard ReLU\n","standard_result = F.relu(test_input)\n","standard_result.sum().backward()\n","print(\"\\nStandard ReLU gradient:\", test_input.grad)\n","\n","# 2. Memory Management - In-place Operations\n","# Create tensors\n","x = torch.randn(1000, 1000, requires_grad=True)\n","y = torch.randn(1000, 1000, requires_grad=True)\n","\n","# Standard operation (creates new memory)\n","def standard_op():\n","    return x + y\n","\n","# In-place operation (reuses memory but has limitations with autograd)\n","def inplace_op():\n","    x_clone = x.clone()\n","    x_clone.add_(y)  # In-place addition (note the underscore)\n","    return x_clone\n","\n","# Memory comparison\n","import sys\n","standard_result = standard_op()\n","inplace_result = inplace_op()\n","\n","# Reset the gradients\n","if x.grad is not None:\n","    x.grad.zero_()\n","if y.grad is not None:\n","    y.grad.zero_()\n","\n","# 3. Performance: CPU vs. GPU (if available)\n","def time_operation(operation, iterations=100):\n","    start_time = time.time()\n","    for _ in range(iterations):\n","        result = operation()\n","        # Force computation to complete\n","        if isinstance(result, torch.Tensor):\n","            result.cpu()\n","    end_time = time.time()\n","    return (end_time - start_time) / iterations * 1000  # ms\n","\n","# Benchmark on CPU\n","a_cpu = torch.randn(1000, 1000)\n","b_cpu = torch.randn(1000, 1000)\n","\n","cpu_time = time_operation(lambda: a_cpu @ b_cpu)\n","print(f\"\\nMatrix multiplication on CPU: {cpu_time:.4f} ms\")\n","\n","# Benchmark on GPU if available\n","if torch.cuda.is_available():\n","    a_gpu = a_cpu.cuda()\n","    b_gpu = b_cpu.cuda()\n","\n","    # Warmup\n","    for _ in range(10):\n","        a_gpu @ b_gpu\n","\n","    # Time GPU operations\n","    gpu_time = time_operation(lambda: a_gpu @ b_gpu)\n","    print(f\"Matrix multiplication on GPU: {gpu_time:.4f} ms\")\n","    print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n","\n","# Memory optimization example: reusing tensors in a loop\n","def inefficient_loop():\n","    result = torch.zeros(10)\n","    for i in range(100):\n","        temp = torch.randn(1000, 1000)  # Creates new tensor each time\n","        result[i % 10] += temp.sum().item()\n","    return result\n","\n","def efficient_loop():\n","    result = torch.zeros(10)\n","    temp = torch.randn(1000, 1000)  # Create tensor once, reuse it\n","    for i in range(100):\n","        temp.normal_()  # In-place random generation\n","        result[i % 10] += temp.sum().item()\n","    return result\n","\n","# Time comparison\n","inefficient_time = time_operation(inefficient_loop, iterations=5)\n","efficient_time = time_operation(efficient_loop, iterations=5)\n","print(f\"\\nInefficient loop time: {inefficient_time:.4f} ms\")\n","print(f\"Efficient loop time: {efficient_time:.4f} ms\")\n","print(f\"Improvement: {inefficient_time / efficient_time:.2f}x\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jNbkW5MNMI1","executionInfo":{"status":"ok","timestamp":1741763715122,"user_tz":420,"elapsed":10031,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"5b6e1f17-76ca-47ef-afdc-4471c8464735"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: tensor([-2., -1.,  0.,  1.,  2.])\n","Output of custom ReLU: tensor([0., 0., 0., 1., 2.])\n","Gradient: tensor([0., 0., 1., 1., 1.])\n","\n","Standard ReLU gradient: tensor([0., 0., 0., 1., 1.])\n","\n","Matrix multiplication on CPU: 39.6601 ms\n","\n","Inefficient loop time: 701.8473 ms\n","Efficient loop time: 496.1609 ms\n","Improvement: 1.41x\n"]}]},{"cell_type":"markdown","source":["## Integration with einops Library\n","\n","The `einops` library provides a powerful and intuitive way to manipulate tensors through operations like rearrange, reduce, and repeat. It offers a more readable alternative to PyTorch's built-in reshaping functions.\n","\n","Let's explore how to use einops with PyTorch:"],"metadata":{"id":"x_t9yn4qNU0B"}},{"cell_type":"code","source":["# Install einops if not already installed\n","!pip install -q einops\n","import einops\n","\n","# Create sample tensor - USING FLOAT DATATYPE\n","x = torch.tensor([\n","    [[1, 2, 3, 4], [5, 6, 7, 8]],\n","    [[9, 10, 11, 12], [13, 14, 15, 16]]\n","], dtype=torch.float32)  # Explicitly use float32\n","print(\"Original tensor shape:\", x.shape)  # [2, 2, 4]\n","print(\"Original tensor:\\n\", x)\n","\n","# Reshaping with einops.rearrange\n","# 'b h w -> b (h w)' means \"convert height and width dimensions into a single dimension\"\n","flattened = einops.rearrange(x, 'b h w -> b (h w)')\n","print(\"\\nFlattened tensor shape:\", flattened.shape)\n","print(\"Flattened tensor:\\n\", flattened)\n","\n","# PyTorch equivalent\n","pytorch_flattened = x.reshape(2, -1)\n","print(\"\\nPyTorch flattened tensor:\\n\", pytorch_flattened)\n","\n","# Transpose with einops\n","# 'b h w -> h b w' means \"move height dimension to batch position\"\n","transposed = einops.rearrange(x, 'b h w -> h b w')\n","print(\"\\nTransposed tensor shape:\", transposed.shape)\n","print(\"Transposed tensor:\\n\", transposed)\n","\n","# PyTorch equivalent\n","pytorch_transposed = x.permute(1, 0, 2)\n","print(\"\\nPyTorch transposed tensor:\\n\", pytorch_transposed)\n","\n","# Reducing dimensions with einops.reduce\n","# 'b h w -> b w' means \"reduce along height dimension by taking mean\"\n","mean_height = einops.reduce(x, 'b h w -> b w', 'mean')\n","print(\"\\nHeight-reduced tensor shape:\", mean_height.shape)\n","print(\"Height-reduced tensor (mean):\\n\", mean_height)\n","\n","# PyTorch equivalent\n","pytorch_mean_height = x.mean(dim=1)\n","print(\"\\nPyTorch height-reduced tensor:\\n\", pytorch_mean_height)\n","\n","# Summing with einops.reduce\n","sum_all = einops.reduce(x, 'b h w -> ', 'sum')\n","print(\"\\nSum of all elements:\", sum_all.item())\n","\n","# Repeating with einops.repeat\n","# 'h w -> b h w' means \"add a batch dimension of size 3\"\n","repeated = einops.repeat(x[0], 'h w -> b h w', b=3)\n","print(\"\\nRepeated tensor shape:\", repeated.shape)\n","print(\"Repeated tensor (first slice repeated 3 times in batch dim):\\n\", repeated)\n","\n","# Complex transformation with einops\n","# Rearrange a batch of images from [batch, height, width, channels] to [batch, channels, height, width]\n","fake_images = torch.randn(4, 16, 16, 3)  # [batch, height, width, channels]\n","rearranged = einops.rearrange(fake_images, 'b h w c -> b c h w')\n","print(\"\\nRearranged images shape:\", rearranged.shape)  # [batch, channels, height, width]\n","\n","# Creating a sliding window view with einops - Fixed approach\n","h, w = 28, 28  # Image dimensions\n","kernel_h, kernel_w = 3, 3  # Kernel dimensions\n","\n","# Create a sample image\n","image = torch.arange(h * w).reshape(1, 1, h, w).float()\n","\n","# Use unfold for cleaner sliding window extraction\n","# This creates a view without copying data\n","patches = image.unfold(2, kernel_h, 1).unfold(3, kernel_w, 1)\n","# Reshape to [batch, num_patches, patch_size]\n","batch_size, channels, output_h, output_w, kh, kw = patches.shape\n","patches = patches.permute(0, 2, 3, 1, 4, 5).reshape(batch_size, output_h * output_w, channels * kh * kw)\n","\n","print(\"\\nPatches from sliding window using unfold:\")\n","print(\"Original image shape:\", image.shape)\n","print(\"Unfolded patches shape:\", patches.shape)\n","print(\"Number of patches:\", patches.shape[1])\n","print(\"Patch size:\", patches.shape[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wy3UXEc7NPhz","executionInfo":{"status":"ok","timestamp":1741763956207,"user_tz":420,"elapsed":2534,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"e3c289a1-fcd5-4809-e858-b589a428dba4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tensor shape: torch.Size([2, 2, 4])\n","Original tensor:\n"," tensor([[[ 1.,  2.,  3.,  4.],\n","         [ 5.,  6.,  7.,  8.]],\n","\n","        [[ 9., 10., 11., 12.],\n","         [13., 14., 15., 16.]]])\n","\n","Flattened tensor shape: torch.Size([2, 8])\n","Flattened tensor:\n"," tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n","        [ 9., 10., 11., 12., 13., 14., 15., 16.]])\n","\n","PyTorch flattened tensor:\n"," tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n","        [ 9., 10., 11., 12., 13., 14., 15., 16.]])\n","\n","Transposed tensor shape: torch.Size([2, 2, 4])\n","Transposed tensor:\n"," tensor([[[ 1.,  2.,  3.,  4.],\n","         [ 9., 10., 11., 12.]],\n","\n","        [[ 5.,  6.,  7.,  8.],\n","         [13., 14., 15., 16.]]])\n","\n","PyTorch transposed tensor:\n"," tensor([[[ 1.,  2.,  3.,  4.],\n","         [ 9., 10., 11., 12.]],\n","\n","        [[ 5.,  6.,  7.,  8.],\n","         [13., 14., 15., 16.]]])\n","\n","Height-reduced tensor shape: torch.Size([2, 4])\n","Height-reduced tensor (mean):\n"," tensor([[ 3.,  4.,  5.,  6.],\n","        [11., 12., 13., 14.]])\n","\n","PyTorch height-reduced tensor:\n"," tensor([[ 3.,  4.,  5.,  6.],\n","        [11., 12., 13., 14.]])\n","\n","Sum of all elements: 136.0\n","\n","Repeated tensor shape: torch.Size([3, 2, 4])\n","Repeated tensor (first slice repeated 3 times in batch dim):\n"," tensor([[[1., 2., 3., 4.],\n","         [5., 6., 7., 8.]],\n","\n","        [[1., 2., 3., 4.],\n","         [5., 6., 7., 8.]],\n","\n","        [[1., 2., 3., 4.],\n","         [5., 6., 7., 8.]]])\n","\n","Rearranged images shape: torch.Size([4, 3, 16, 16])\n","\n","Patches from sliding window using unfold:\n","Original image shape: torch.Size([1, 1, 28, 28])\n","Unfolded patches shape: torch.Size([1, 676, 9])\n","Number of patches: 676\n","Patch size: 9\n"]}]},{"cell_type":"code","source":["# Memory Management in PyTorch - Essential Techniques\n","\n","# 1. Basic memory tracking\n","if torch.cuda.is_available():\n","    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1e6:.2f} MB\")\n","    print(f\"GPU memory reserved: {torch.cuda.memory_reserved() / 1e6:.2f} MB\")\n","\n","# 2. Create tensors (without pinning to avoid GPU dependency)\n","tensor_a = torch.randn(1000, 1000)\n","tensor_b = torch.randn(1000, 1000)\n","\n","# 3. No gradient tracking for inference\n","with torch.no_grad():\n","    output = tensor_a @ tensor_b\n","\n","# 4. In-place operations to save memory\n","x = torch.ones(1000)\n","x.add_(5)  # In-place addition (note the underscore)\n","\n","# 5. Other in-place operations\n","y = torch.randn(10, 10)\n","y.zero_()  # Fill with zeros in-place\n","z = torch.ones(10, 10)\n","z.fill_(3.14)  # Fill with value in-place\n","\n","# 6. Make non-contiguous tensors contiguous for performance\n","a = torch.randn(10, 10)\n","a_t = a.t()  # Transpose makes tensor non-contiguous\n","a_t_cont = a_t.contiguous()  # Make contiguous for better performance\n","\n","# 7. Clear unused tensors\n","del tensor_a, tensor_b\n","\n","print(\"Memory management best practices in PyTorch:\")\n","print(\"1. Use in-place operations (tensor.add_() instead of tensor + value)\")\n","print(\"2. Use torch.no_grad() for inference\")\n","print(\"3. Explicitly delete unused tensors with 'del'\")\n","print(\"4. Call torch.cuda.empty_cache() when needed\")\n","print(\"5. Use .to(device) to move tensors between CPU and GPU\")\n","print(\"6. Make tensors contiguous with .contiguous() for better performance\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpqDYNWZNTOP","executionInfo":{"status":"ok","timestamp":1741764078113,"user_tz":420,"elapsed":153,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"45ba08f1-b062-4f11-d1d3-e85011f46133"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory management best practices in PyTorch:\n","1. Use in-place operations (tensor.add_() instead of tensor + value)\n","2. Use torch.no_grad() for inference\n","3. Explicitly delete unused tensors with 'del'\n","4. Call torch.cuda.empty_cache() when needed\n","5. Use .to(device) to move tensors between CPU and GPU\n","6. Make tensors contiguous with .contiguous() for better performance\n"]}]},{"cell_type":"code","source":["# Create a comparison summary\n","print(\"## Comparing TensorFlow and PyTorch ##\\n\")\n","\n","print(\"TensorFlow Advantages:\")\n","print(\"âœ“ Strong deployment ecosystem (TF Serving, TFLite, TFX)\")\n","print(\"âœ“ Excellent production-ready tools\")\n","print(\"âœ“ Compatible with various hardware accelerators (TPUs)\")\n","print(\"âœ“ Static graph optimization for performance\")\n","print(\"âœ“ Keras integration for high-level model building\")\n","\n","print(\"\\nPyTorch Advantages:\")\n","print(\"âœ“ Pythonic API and intuitive design\")\n","print(\"âœ“ Dynamic computation graph\")\n","print(\"âœ“ Easier debugging experience\")\n","print(\"âœ“ Popular in research communities\")\n","print(\"âœ“ Natural implementation of dynamic neural networks\")\n","\n","print(\"\\nCommon Features:\")\n","print(\"âœ“ Tensor operations (creation, reshaping, mathematical operations)\")\n","print(\"âœ“ Automatic differentiation\")\n","print(\"âœ“ GPU acceleration\")\n","print(\"âœ“ Deep learning primitives\")\n","print(\"âœ“ Support for distributed training\")\n","\n","print(\"\\nSample Neural Network Implementation Comparison:\")\n","\n","print(\"\\nTensorFlow:\")\n","print(\"\"\"\n","# Define model\n","class SimpleModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10)\n","\n","    def call(self, x):\n","        x = self.dense1(x)\n","        return self.dense2(x)\n","\n","# Compile and train\n","model = SimpleModel()\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train, epochs=5, batch_size=32)\n","\"\"\")\n","\n","print(\"\\nPyTorch:\")\n","print(\"\"\"\n","# Define model\n","class SimpleModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.dense1 = nn.Linear(784, 128)\n","        self.dense2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.dense1(x))\n","        return self.dense2(x)\n","\n","# Training loop\n","model = SimpleModel()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","for epoch in range(5):\n","    for batch_x, batch_y in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1m5C116eObAH","executionInfo":{"status":"ok","timestamp":1741764150028,"user_tz":420,"elapsed":29,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"fe8cad39-63ec-40a5-e666-1bfed7c38204"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["## Comparing TensorFlow and PyTorch ##\n","\n","TensorFlow Advantages:\n","âœ“ Strong deployment ecosystem (TF Serving, TFLite, TFX)\n","âœ“ Excellent production-ready tools\n","âœ“ Compatible with various hardware accelerators (TPUs)\n","âœ“ Static graph optimization for performance\n","âœ“ Keras integration for high-level model building\n","\n","PyTorch Advantages:\n","âœ“ Pythonic API and intuitive design\n","âœ“ Dynamic computation graph\n","âœ“ Easier debugging experience\n","âœ“ Popular in research communities\n","âœ“ Natural implementation of dynamic neural networks\n","\n","Common Features:\n","âœ“ Tensor operations (creation, reshaping, mathematical operations)\n","âœ“ Automatic differentiation\n","âœ“ GPU acceleration\n","âœ“ Deep learning primitives\n","âœ“ Support for distributed training\n","\n","Sample Neural Network Implementation Comparison:\n","\n","TensorFlow:\n","\n","# Define model\n","class SimpleModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10)\n","        \n","    def call(self, x):\n","        x = self.dense1(x)\n","        return self.dense2(x)\n","\n","# Compile and train\n","model = SimpleModel()\n","model.compile(optimizer='adam', \n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train, epochs=5, batch_size=32)\n","\n","\n","PyTorch:\n","\n","# Define model\n","class SimpleModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.dense1 = nn.Linear(784, 128)\n","        self.dense2 = nn.Linear(128, 10)\n","        \n","    def forward(self, x):\n","        x = torch.relu(self.dense1(x))\n","        return self.dense2(x)\n","\n","# Training loop\n","model = SimpleModel()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","for epoch in range(5):\n","    for batch_x, batch_y in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"neX9gS8JO8Ji"},"execution_count":null,"outputs":[]}]}