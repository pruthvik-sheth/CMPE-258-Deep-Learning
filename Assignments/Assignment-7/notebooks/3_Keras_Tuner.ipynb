{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMWEEM3eVjWZup0zeZZziJ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Hyperparameter Tuning with Keras Tuner\n","\n","This notebook demonstrates how to use Keras Tuner to automatically find optimal hyperparameters for your deep learning models. We'll explore how to:\n","\n","1. Define a hyperparameter search space\n","2. Use different search strategies (Random, Hyperband, Bayesian)\n","3. Analyze and visualize tuning results\n","4. Build the best model with the optimal hyperparameters"],"metadata":{"id":"iOpxbJ7szAvB"}},{"cell_type":"markdown","source":["## Keras Tuner Setup\n","\n","This code prepares our environment for hyperparameter tuning with Keras Tuner, using a reduced dataset size for faster experimentation."],"metadata":{"id":"9WI0nTmSy9RO"}},{"cell_type":"code","source":["!pip install keras-tuner"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haZrT_dOzZKr","executionInfo":{"status":"ok","timestamp":1746152736474,"user_tz":420,"elapsed":7652,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"b284802f-c282-4607-b24a-10bc09f52b2e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n","Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4zO1Rk-y47D","executionInfo":{"status":"ok","timestamp":1746152748811,"user_tz":420,"elapsed":12336,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"029b8ecc-19a8-494b-d876-8a6e2605cd46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Training sample shape: (10000, 28, 28)\n","Validation sample shape: (2000, 28, 28)\n"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n","import keras_tuner as kt\n","import matplotlib.pyplot as plt\n","\n","# Load and preprocess the Fashion MNIST dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n","\n","# Use smaller dataset for faster tuning\n","train_size = 10000\n","val_size = 2000\n","x_train_sample = x_train[:train_size]\n","y_train_sample = y_train[:train_size]\n","x_val_sample = x_train[train_size:train_size+val_size]\n","y_val_sample = y_train[train_size:train_size+val_size]\n","\n","print(f\"Training sample shape: {x_train_sample.shape}\")\n","print(f\"Validation sample shape: {x_val_sample.shape}\")"]},{"cell_type":"markdown","source":["## Defining the Hyperparameter Search Space\n","\n","This function defines a model architecture with tunable hyperparameters, including:\n","- Layer sizes (units in dense layers)\n","- Dropout rate\n","- Whether to include batch normalization\n","- Learning rate\n","\n","Keras Tuner will systematically explore this space to find optimal combinations."],"metadata":{"id":"JA0Pun3cztpZ"}},{"cell_type":"code","source":["# Define the model-building function with hyperparameters to tune\n","def build_model(hp):\n","    model = Sequential()\n","    model.add(Flatten(input_shape=(28, 28)))\n","\n","    # Tune number of units in first dense layer\n","    hp_units1 = hp.Int('units_1', min_value=32, max_value=256, step=32)\n","    model.add(Dense(hp_units1, activation='relu'))\n","\n","    # Tune dropout rate\n","    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n","    model.add(Dropout(hp_dropout))\n","\n","    # Tune whether to include batch normalization\n","    if hp.Boolean('batch_normalization'):\n","        model.add(BatchNormalization())\n","\n","    # Tune number of units in second dense layer\n","    hp_units2 = hp.Int('units_2', min_value=16, max_value=128, step=16)\n","    model.add(Dense(hp_units2, activation='relu'))\n","\n","    model.add(Dense(10, activation='softmax'))\n","\n","    # Tune learning rate\n","    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 5e-3, 1e-2])\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model"],"metadata":{"id":"nj6zseUlzsEw","executionInfo":{"status":"ok","timestamp":1746152748830,"user_tz":420,"elapsed":9,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter Tuning with Random Search\n","\n","We use Keras Tuner's RandomSearch to find optimal hyperparameters, limiting to 5 trials for efficiency. The tuner automatically tests different combinations and identifies the best performing model configuration."],"metadata":{"id":"s_UKj3VfzwRX"}},{"cell_type":"code","source":["# Initialize the Random Search tuner\n","tuner = kt.RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5,  # Limit to 5 trials for brevity\n","    executions_per_trial=1,\n","    directory='keras_tuner',\n","    project_name='fashion_mnist'\n",")\n","\n","# Define early stopping callback for each trial\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","\n","# Start the search\n","tuner.search(\n","    x_train_sample, y_train_sample,\n","    epochs=5,\n","    validation_data=(x_val_sample, y_val_sample),\n","    callbacks=[stop_early],\n","    verbose=1\n",")\n","\n","# Get the best hyperparameters and build the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","best_model = tuner.hypermodel.build(best_hps)\n","\n","# Print the best hyperparameters\n","print(\"Best Hyperparameters:\")\n","print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n","print(f\"Units in first layer: {best_hps.get('units_1')}\")\n","print(f\"Units in second layer: {best_hps.get('units_2')}\")\n","print(f\"Dropout rate: {best_hps.get('dropout')}\")\n","print(f\"Batch normalization: {best_hps.get('batch_normalization')}\")\n","\n","# Train the best model\n","best_model.fit(\n","    x_train_sample, y_train_sample,\n","    epochs=5,\n","    validation_data=(x_val_sample, y_val_sample),\n","    verbose=1\n",")\n","\n","# Evaluate on test set\n","test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=1)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyUy2j1ezDbI","executionInfo":{"status":"ok","timestamp":1746152832723,"user_tz":420,"elapsed":83891,"user":{"displayName":"Pruthvik Sheth","userId":"03427505168681154907"}},"outputId":"686305bd-fefc-4ad2-d570-916f6e1bf252"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 12s]\n","val_accuracy: 0.8339999914169312\n","\n","Best val_accuracy So Far: 0.8619999885559082\n","Total elapsed time: 00h 01m 10s\n","Best Hyperparameters:\n","Learning rate: 0.001\n","Units in first layer: 224\n","Units in second layer: 32\n","Dropout rate: 0.1\n","Batch normalization: False\n","Epoch 1/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6489 - loss: 1.0209 - val_accuracy: 0.8250 - val_loss: 0.5126\n","Epoch 2/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.5264 - val_accuracy: 0.8445 - val_loss: 0.4362\n","Epoch 3/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4279 - val_accuracy: 0.8520 - val_loss: 0.4316\n","Epoch 4/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.4172 - val_accuracy: 0.8590 - val_loss: 0.4207\n","Epoch 5/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.3722 - val_accuracy: 0.8605 - val_loss: 0.4045\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4350\n","Test accuracy: 0.8423\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"f_ddXKjUzkVC"},"execution_count":null,"outputs":[]}]}