{"cells":[{"cell_type":"markdown","source":["# Building a Conversational Chatbot\n","\n","This notebook demonstrates how to create a simple but functional chatbot using Hugging Face's Transformers library. We'll start by installing the necessary dependencies."],"metadata":{"id":"9sCGwpSO9XQ7"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lh_LCGYCzfcZ","outputId":"63f4bc6b-04d1-43e1-c120-7ccfe5b386d8","executionInfo":{"status":"ok","timestamp":1745920312495,"user_tz":420,"elapsed":13421,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m194.6/194.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Install required libraries\n","!pip install -q transformers datasets"]},{"cell_type":"markdown","source":["## Import Dependencies\n","\n","This cell imports all the necessary libraries for our conversational chatbot. We need PyTorch for the deep learning components, transformers for the language model, and various utilities for data handling and visualization."],"metadata":{"id":"zkniUbQk9aQq"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"DGuaiQujzfZe","executionInfo":{"status":"ok","timestamp":1745920346459,"user_tz":420,"elapsed":33958,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Import necessary libraries\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from datasets import load_dataset\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import re\n","from IPython.display import display, HTML"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uxycWgOzfWr","outputId":"8512448d-cc41-4073-d3d8-08c1f88c430b","executionInfo":{"status":"ok","timestamp":1745920485683,"user_tz":420,"elapsed":5,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["# Determine the available computing device\n","compute_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {compute_device}\")"]},{"cell_type":"markdown","source":["## Load Model and Tokenizer\n","\n","This cell loads the pretrained language model and its associated tokenizer. We're using a smaller model (BlenderBot) for demonstration purposes, but you could substitute a larger model for better performance if your hardware allows."],"metadata":{"id":"rYRYG50l9hoY"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcpJcs1ozfUM","outputId":"b300fd00-73e5-4613-881f-496e700e8b53","executionInfo":{"status":"ok","timestamp":1745920488844,"user_tz":420,"elapsed":1938,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model: facebook/blenderbot-400M-distill\n","Model and tokenizer loaded successfully!\n"]}],"source":["# Initialize the language model and tokenizer\n","selected_model = \"facebook/blenderbot-400M-distill\"\n","print(f\"Loading model: {selected_model}\")\n","\n","# Load the components from Hugging Face\n","tokenizer = AutoTokenizer.from_pretrained(selected_model)\n","model = AutoModelForCausalLM.from_pretrained(selected_model).to(compute_device)\n","\n","print(\"Model and tokenizer loaded successfully!\")"]},{"cell_type":"markdown","source":["## Helper Functions for Chat Processing\n","\n","This cell defines utility functions for formatting conversations and generating responses. These functions handle the conversation flow, including formatting messages based on their role (user or assistant) and using the model to generate appropriate responses."],"metadata":{"id":"CArgy_BF9kaC"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"hdUD2CUtzrY3","executionInfo":{"status":"ok","timestamp":1745920490744,"user_tz":420,"elapsed":2,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Define helper functions for conversation management\n","\n","def create_message_format(speaker_role, message_text):\n","    \"\"\"Format a message based on who is speaking\"\"\"\n","    if speaker_role == \"user\":\n","        return f\"User: {message_text}\"\n","    else:\n","        return f\"Assistant: {message_text}\"\n","\n","def compile_conversation_history(message_list):\n","    \"\"\"Convert the list of messages into a formatted conversation string\"\"\"\n","    return \"\\n\".join([create_message_format(msg[\"role\"], msg[\"content\"]) for msg in message_list])\n","\n","def create_bot_response(message_list, response_length=128):\n","    \"\"\"Generate the assistant's response based on conversation context\"\"\"\n","    # Format the full conversation history\n","    formatted_history = compile_conversation_history(message_list)\n","\n","    # Add the assistant prefix for the new response\n","    full_prompt = formatted_history + \"\\nAssistant:\"\n","\n","    # Convert to model input format\n","    encoded_input = tokenizer(full_prompt, return_tensors=\"pt\").to(compute_device)\n","\n","    # Generate response without calculating gradients\n","    with torch.no_grad():\n","        generated_ids = model.generate(\n","            encoded_input[\"input_ids\"],\n","            max_length=encoded_input[\"input_ids\"].shape[1] + response_length,\n","            temperature=0.7,\n","            top_p=0.9,\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","    # Convert token IDs back to text\n","    complete_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    # Extract only the assistant's new response\n","    bot_response = complete_output.split(\"Assistant:\")[-1].strip()\n","\n","    return bot_response"]},{"cell_type":"markdown","source":["## Basic Chat Interface\n","\n","This cell implements a simple text-based chat interface that allows users to interact with the chatbot in the console. It handles the conversation flow, maintains conversation history, and displays the bot's responses."],"metadata":{"id":"APiVjxcG9rL2"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"Pk1MMWVTzyrk","executionInfo":{"status":"ok","timestamp":1745920492544,"user_tz":420,"elapsed":1,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Implement a simple console-based chat interface\n","conversation_history = []\n","\n","def start_text_chat():\n","    \"\"\"Start an interactive text-based chat with the bot\"\"\"\n","    print(\"\\n===== Conversational Chatbot Demo =====\")\n","    print(\"Type 'exit' to end the conversation\\n\")\n","\n","    while True:\n","        # Get input from the user\n","        user_message = input(\"User: \")\n","\n","        # Check if user wants to exit\n","        if user_message.lower() == \"exit\":\n","            print(\"\\nThank you for chatting! Goodbye.\")\n","            break\n","\n","        # Store the user's message\n","        conversation_history.append({\"role\": \"user\", \"content\": user_message})\n","\n","        # Indicate that the model is processing\n","        print(\"Assistant is thinking...\")\n","\n","        # Generate and get response\n","        bot_message = create_bot_response(conversation_history)\n","\n","        # Store the bot's response\n","        conversation_history.append({\"role\": \"assistant\", \"content\": bot_message})\n","\n","        # Display the response\n","        print(f\"Assistant: {bot_message}\\n\")"]},{"cell_type":"markdown","source":["## Enhanced Chatbot Features\n","\n","This cell implements advanced features to make our chatbot more dynamic and contextually aware:\n","1. Persona customization - allows changing the bot's personality\n","2. Memory management - for clearing or summarizing conversations\n","3. Sentiment analysis - to detect the emotional tone of messages"],"metadata":{"id":"_jeB-CBY9t7X"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"HdfwzGJtz1KK","executionInfo":{"status":"ok","timestamp":1745920494180,"user_tz":420,"elapsed":17,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Implement enhanced chatbot features\n","\n","# Feature 1: Bot persona customization\n","def configure_bot_personality(personality_description):\n","    \"\"\"Configure the chatbot's personality\"\"\"\n","    # Check if there's already a system message\n","    if len(conversation_history) == 0 or conversation_history[0][\"role\"] != \"system\":\n","        # Add a new system message at the beginning\n","        conversation_history.insert(0, {\"role\": \"system\", \"content\": personality_description})\n","    else:\n","        # Update existing system message\n","        conversation_history[0] = {\"role\": \"system\", \"content\": personality_description}\n","    print(f\"Bot personality configured as: {personality_description}\")\n","\n","# Feature 2: Conversation management\n","def reset_conversation():\n","    \"\"\"Clear the entire conversation history\"\"\"\n","    conversation_history.clear()\n","    print(\"Conversation history has been reset.\")\n","\n","def create_conversation_summary():\n","    \"\"\"Generate a brief summary of the current conversation\"\"\"\n","    # Check if there's enough conversation to summarize\n","    if len(conversation_history) <= 2:\n","        return \"The conversation has just begun.\"\n","\n","    # Create a prompt for summarization\n","    summary_prompt = \"Summarize this conversation:\\n\\n\" + compile_conversation_history(conversation_history)\n","\n","    # Use the model to generate a summary\n","    encoded_input = tokenizer(summary_prompt, return_tensors=\"pt\").to(compute_device)\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            encoded_input[\"input_ids\"],\n","            max_length=encoded_input[\"input_ids\"].shape[1] + 100,\n","            temperature=0.7,\n","            top_p=0.9,\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","    # Extract just the summary (removing the original prompt)\n","    full_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","    summary_text = full_output.replace(summary_prompt, \"\").strip()\n","    return summary_text\n","\n","# Feature 3: Basic sentiment detection\n","def detect_message_sentiment(message_text):\n","    \"\"\"Perform simple keyword-based sentiment analysis\"\"\"\n","    # Define sentiment indicator words\n","    positive_indicators = [\"good\", \"great\", \"happy\", \"positive\", \"excellent\",\n","                          \"wonderful\", \"love\", \"like\", \"enjoy\"]\n","    negative_indicators = [\"bad\", \"terrible\", \"sad\", \"negative\", \"awful\",\n","                          \"horrible\", \"hate\", \"dislike\", \"disappointing\"]\n","\n","    # Convert to lowercase for comparison\n","    message_text = message_text.lower()\n","\n","    # Count occurrences of sentiment words\n","    positive_matches = sum(1 for word in positive_indicators if word in message_text)\n","    negative_matches = sum(1 for word in negative_indicators if word in message_text)\n","\n","    # Determine overall sentiment\n","    if positive_matches > negative_matches:\n","        return \"positive\"\n","    elif negative_matches > positive_matches:\n","        return \"negative\"\n","    else:\n","        return \"neutral\""]},{"cell_type":"markdown","source":["## Interactive Widget-Based Interface\n","\n","This cell creates a more user-friendly interface using iPython widgets. It provides a text input field, buttons for sending messages and clearing the chat, and a dropdown menu to select different bot personas. This interface is particularly useful in notebook environments like Colab."],"metadata":{"id":"FUreQhUg95BM"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"E4Uady7Mz45l","executionInfo":{"status":"ok","timestamp":1745920495736,"user_tz":420,"elapsed":2,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Create an interactive widget-based chat interface\n","from IPython.display import display, HTML\n","import ipywidgets as widgets\n","\n","def launch_widget_interface():\n","    \"\"\"Launch an interactive widget-based chat interface\"\"\"\n","    # Create the interface widgets\n","    chat_display = widgets.Output()\n","    message_input = widgets.Text(placeholder=\"Type your message here...\")\n","    send_button = widgets.Button(description=\"Send\")\n","    clear_button = widgets.Button(description=\"Clear Chat\")\n","\n","    # Create persona selection dropdown\n","    personality_selector = widgets.Dropdown(\n","        options=[\n","            'Helpful Assistant',\n","            'Travel Guide',\n","            'Tech Support',\n","            'Friendly Friend',\n","            'Professional Colleague'\n","        ],\n","        value='Helpful Assistant',\n","        description='Bot Persona:'\n","    )\n","\n","    # Display the interface components\n","    display(HTML(\"<h3>Conversational Chatbot</h3>\"))\n","    display(personality_selector)\n","    display(widgets.HBox([message_input, send_button, clear_button]))\n","    display(chat_display)\n","\n","    # Initialize the chat\n","    chat_messages = []\n","    configure_bot_personality(\"You are a helpful, respectful and honest assistant.\")\n","\n","    # Define button handlers\n","    def handle_send_button(button):\n","        user_text = message_input.value\n","        if not user_text.strip():\n","            return\n","\n","        # Clear input field\n","        message_input.value = \"\"\n","\n","        # Add user message to conversation\n","        chat_messages.append({\"role\": \"user\", \"content\": user_text})\n","\n","        with chat_display:\n","            print(f\"User: {user_text}\")\n","            print(\"Assistant is thinking...\")\n","\n","            # Generate the bot's response\n","            bot_text = create_bot_response(chat_messages)\n","\n","            # Add bot message to conversation\n","            chat_messages.append({\"role\": \"assistant\", \"content\": bot_text})\n","\n","            print(f\"Assistant: {bot_text}\\n\")\n","\n","    def handle_clear_button(button):\n","        with chat_display:\n","            chat_display.clear_output()\n","            chat_messages.clear()\n","            # Apply the current persona\n","            selected_persona = personality_selector.value\n","            if selected_persona == \"Helpful Assistant\":\n","                configure_bot_personality(\"You are a helpful, respectful and honest assistant.\")\n","            elif selected_persona == \"Travel Guide\":\n","                configure_bot_personality(\"You are a knowledgeable travel guide who provides detailed information about destinations, travel tips, and local customs.\")\n","            elif selected_persona == \"Tech Support\":\n","                configure_bot_personality(\"You are a patient technical support specialist who helps users troubleshoot their computer and software issues.\")\n","            elif selected_persona == \"Friendly Friend\":\n","                configure_bot_personality(\"You are a friendly and supportive friend who offers empathy, advice, and casual conversation.\")\n","            elif selected_persona == \"Professional Colleague\":\n","                configure_bot_personality(\"You are a professional colleague who communicates in a business-appropriate manner, focusing on tasks and efficiency.\")\n","            print(\"Chat has been cleared. You can start a new conversation.\")\n","\n","    def handle_persona_change(change):\n","        if change['type'] == 'change' and change['name'] == 'value':\n","            with chat_display:\n","                if change['new'] == \"Helpful Assistant\":\n","                    configure_bot_personality(\"You are a helpful, respectful and honest assistant.\")\n","                elif change['new'] == \"Travel Guide\":\n","                    configure_bot_personality(\"You are a knowledgeable travel guide who provides detailed information about destinations, travel tips, and local customs.\")\n","                elif change['new'] == \"Tech Support\":\n","                    configure_bot_personality(\"You are a patient technical support specialist who helps users troubleshoot their computer and software issues.\")\n","                elif change['new'] == \"Friendly Friend\":\n","                    configure_bot_personality(\"You are a friendly and supportive friend who offers empathy, advice, and casual conversation.\")\n","                elif change['new'] == \"Professional Colleague\":\n","                    configure_bot_personality(\"You are a professional colleague who communicates in a business-appropriate manner, focusing on tasks and efficiency.\")\n","                print(f\"Bot persona changed to: {change['new']}\")\n","\n","    # Connect the event handlers\n","    send_button.on_click(handle_send_button)\n","    clear_button.on_click(handle_clear_button)\n","    personality_selector.observe(handle_persona_change)\n","\n","    # Enable sending messages with Enter key\n","    def handle_keypress(change):\n","        if change['type'] == 'change' and change['name'] == 'value':\n","            if change['new'].endswith('\\n'):\n","                message_input.value = change['new'].rstrip('\\n')\n","                handle_send_button(None)\n","\n","    message_input.observe(handle_keypress)"]},{"cell_type":"markdown","source":["## Evaluation Functions\n","\n","This cell implements functions for evaluating the quality of the chatbot's responses. It includes:\n","1. A response quality evaluator with multiple criteria\n","2. A test suite with pre-defined conversation scenarios\n","\n","These tools help assess the bot's performance across different types of interactions."],"metadata":{"id":"Wgu7BGnC98y_"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"wrRBcJ7uz8Hi","executionInfo":{"status":"ok","timestamp":1745920497009,"user_tz":420,"elapsed":9,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[],"source":["# Functions for evaluating the chatbot's performance\n","\n","def assess_response_quality(response_text, evaluation_criteria=None):\n","    \"\"\"Evaluate a bot response based on multiple quality criteria\"\"\"\n","    if evaluation_criteria is None:\n","        evaluation_criteria = {\n","            \"relevance\": \"Is the response relevant to the user's message?\",\n","            \"helpfulness\": \"Is the response helpful?\",\n","            \"fluency\": \"Is the response well-written and fluent?\",\n","            \"safety\": \"Is the response safe and appropriate?\"\n","        }\n","\n","    evaluation_scores = {}\n","    print(\"Response Quality Assessment:\")\n","    print(\"-\" * 40)\n","    print(f\"Response: {response_text}\")\n","    print(\"-\" * 40)\n","\n","    # Evaluate each criterion\n","    for criterion, description in evaluation_criteria.items():\n","        # Using simple heuristics for demonstration purposes\n","        if criterion == \"fluency\":\n","            # Base score on sentence structure and length\n","            score = min(10, max(1, len(response_text.split()) / 5))\n","        elif criterion == \"relevance\":\n","            # Using default score (would need context for better evaluation)\n","            score = 7\n","        elif criterion == \"helpfulness\":\n","            # Base score on response length (simple heuristic)\n","            score = min(10, max(1, len(response_text) / 20))\n","        elif criterion == \"safety\":\n","            # Check for potentially problematic terms\n","            concerning_terms = [\"kill\", \"harm\", \"illegal\", \"violent\", \"dangerous\"]\n","            if any(term in response_text.lower() for term in concerning_terms):\n","                score = 3\n","            else:\n","                score = 9\n","\n","        # Record and display the score\n","        evaluation_scores[criterion] = score\n","        print(f\"{criterion.capitalize()} ({description}): {score}/10\")\n","\n","    # Calculate overall score\n","    average_score = sum(evaluation_scores.values()) / len(evaluation_scores)\n","    print(f\"Overall Score: {average_score:.2f}/10\")\n","    return evaluation_scores\n","\n","def run_predefined_tests():\n","    \"\"\"Test the chatbot with predefined conversation scenarios\"\"\"\n","    test_scenarios = [\n","        {\n","            \"name\": \"Initial greeting\",\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": \"Hello there!\"}\n","            ]\n","        },\n","        {\n","            \"name\": \"Information request\",\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": \"Can you recommend some good movies to watch?\"}\n","            ]\n","        },\n","        {\n","            \"name\": \"Multi-turn conversation\",\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": \"I'm planning a vacation.\"},\n","                {\"role\": \"assistant\", \"content\": \"That sounds exciting! Where are you thinking of going?\"},\n","                {\"role\": \"user\", \"content\": \"I'm considering either Italy or Spain.\"}\n","            ]\n","        },\n","        {\n","            \"name\": \"Problem solving\",\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": \"My smartphone battery drains very quickly. What can I do?\"}\n","            ]\n","        }\n","    ]\n","\n","    print(\"Running Test Scenarios:\")\n","    for scenario in test_scenarios:\n","        print(\"\\n\" + \"=\" * 50)\n","        print(f\"Scenario: {scenario['name']}\")\n","        print(\"=\" * 50)\n","\n","        # Create a fresh conversation for each test\n","        test_conversation = []\n","\n","        # Process the scenario messages\n","        for message in scenario[\"messages\"]:\n","            test_conversation.append(message)\n","            print(f\"{message['role'].capitalize()}: {message['content']}\")\n","\n","        # Generate response if the last message is from the user\n","        if test_conversation[-1][\"role\"] == \"user\":\n","            print(\"\\nGenerating response...\")\n","            bot_response = create_bot_response(test_conversation)\n","            print(f\"Assistant: {bot_response}\")\n","\n","            # Evaluate the response quality\n","            assess_response_quality(bot_response)\n","\n","    print(\"\\nAll test scenarios completed!\")"]},{"cell_type":"markdown","source":["## Utility Functions and Main Execution\n","\n","This final cell includes additional utility functions for managing conversations (saving, loading, analyzing) and the main execution block that allows users to select which demo to run. Options include a text-based chat, an interactive widget interface, or automated test scenarios."],"metadata":{"id":"W4ppaCh9-AiA"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c15HiwHpz_J1","outputId":"ca7e33ba-d67a-4dd9-9842-1c95588f7a0f","executionInfo":{"status":"ok","timestamp":1745920566055,"user_tz":420,"elapsed":67549,"user":{"displayName":"Pruthvik Sheth","userId":"09129679688770628333"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Chatbot System Initialized!\n","Select an option:\n","1: Start text-based chat\n","2: Launch interactive widget interface (best in Colab)\n","3: Run test scenarios\n","4: Exit\n","Enter your choice (1-4): 1\n","\n","===== Conversational Chatbot Demo =====\n","Type 'exit' to end the conversation\n","\n","User: Hey How are you?\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["Assistant is thinking...\n","Assistant: Thank you very much.\n","\n","User: Can you explain me machine learning in simple terms\n","Assistant is thinking...\n","Assistant: etc.\n","\n","User: 4\n","Assistant is thinking...\n","Assistant: etc. etc.\n","\n","User: Exit\n","\n","Thank you for chatting! Goodbye.\n"]}],"source":["# Additional utility functions and main execution\n","\n","def export_conversation(filename=\"chatbot_session.txt\"):\n","    \"\"\"Save the current conversation to a text file\"\"\"\n","    with open(filename, \"w\") as file:\n","        file.write(compile_conversation_history(conversation_history))\n","    print(f\"Conversation saved to {filename}\")\n","\n","def import_conversation(filename=\"chatbot_session.txt\"):\n","    \"\"\"Load a conversation from a text file\"\"\"\n","    try:\n","        with open(filename, \"r\") as file:\n","            content = file.read()\n","\n","        # Parse the file content into message format\n","        parsed_messages = []\n","        for line in content.split(\"\\n\"):\n","            if line.startswith(\"User: \"):\n","                parsed_messages.append({\"role\": \"user\", \"content\": line[6:]})\n","            elif line.startswith(\"Assistant: \"):\n","                parsed_messages.append({\"role\": \"assistant\", \"content\": line[11:]})\n","\n","        # Update the conversation history\n","        conversation_history.clear()\n","        conversation_history.extend(parsed_messages)\n","        print(f\"Conversation loaded from {filename}\")\n","    except Exception as e:\n","        print(f\"Error loading conversation: {e}\")\n","\n","def show_conversation_analytics():\n","    \"\"\"Display statistics and analytics about the conversation\"\"\"\n","    if not conversation_history:\n","        print(\"No conversation data to analyze.\")\n","        return\n","\n","    # Count messages by role\n","    user_message_count = sum(1 for msg in conversation_history if msg[\"role\"] == \"user\")\n","    assistant_message_count = sum(1 for msg in conversation_history if msg[\"role\"] == \"assistant\")\n","\n","    # Calculate average message lengths\n","    user_message_lengths = [len(msg[\"content\"]) for msg in conversation_history if msg[\"role\"] == \"user\"]\n","    assistant_message_lengths = [len(msg[\"content\"]) for msg in conversation_history if msg[\"role\"] == \"assistant\"]\n","\n","    avg_user_length = sum(user_message_lengths) / len(user_message_lengths) if user_message_lengths else 0\n","    avg_assistant_length = sum(assistant_message_lengths) / len(assistant_message_lengths) if assistant_message_lengths else 0\n","\n","    # Display analytics\n","    print(\"\\n===== Conversation Analytics =====\")\n","    print(f\"Total messages: {len(conversation_history)}\")\n","    print(f\"User messages: {user_message_count}\")\n","    print(f\"Assistant messages: {assistant_message_count}\")\n","    print(f\"Average user message length: {avg_user_length:.1f} characters\")\n","    print(f\"Average assistant message length: {avg_assistant_length:.1f} characters\")\n","\n","    # Analyze overall sentiment\n","    all_user_content = \" \".join([msg[\"content\"] for msg in conversation_history if msg[\"role\"] == \"user\"])\n","    overall_sentiment = detect_message_sentiment(all_user_content)\n","    print(f\"Overall conversation sentiment: {overall_sentiment}\")\n","\n","# Main execution block\n","if __name__ == \"__main__\":\n","    print(\"\\nChatbot System Initialized!\")\n","    print(\"Select an option:\")\n","    print(\"1: Start text-based chat\")\n","    print(\"2: Launch interactive widget interface (best in Colab)\")\n","    print(\"3: Run test scenarios\")\n","    print(\"4: Exit\")\n","\n","    user_choice = input(\"Enter your choice (1-4): \")\n","\n","    if user_choice == \"1\":\n","        start_text_chat()\n","    elif user_choice == \"2\":\n","        launch_widget_interface()\n","    elif user_choice == \"3\":\n","        run_predefined_tests()\n","    else:\n","        print(\"Exiting program. Goodbye!\")"]},{"cell_type":"code","source":[],"metadata":{"id":"r-CS3Nzgmg09"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}